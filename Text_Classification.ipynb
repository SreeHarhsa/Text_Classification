{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "z7GHJWo3eptK"
      },
      "outputs": [],
      "source": [
        "!pip install -q kaggle"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir ~/.kaggle"
      ],
      "metadata": {
        "id": "E82K9zSGfVFt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "334f7d83-c0f0-410e-bdeb-8e73e3a5b8a7"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘/root/.kaggle’: File exists\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp kaggle.json ~/.kaggle/"
      ],
      "metadata": {
        "id": "7SJFQ0m7fcw5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3bac1435-2cea-441d-ee48-6ddf04652b62"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cp: cannot stat 'kaggle.json': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d shanegerami/ai-vs-human-text"
      ],
      "metadata": {
        "id": "qNyL_tnQfhME",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b6f6d2c-3127-41e7-fc4d-89436e4fc4fc"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/shanegerami/ai-vs-human-text\n",
            "License(s): other\n",
            "ai-vs-human-text.zip: Skipping, found more recently modified local copy (use --force to force download)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/ai-vs-human-text.zip"
      ],
      "metadata": {
        "id": "pFfOzzODft2Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6df7f682-cb14-4245-d21d-e0b96dcfea4e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/ai-vs-human-text.zip\n",
            "replace AI_Human.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk"
      ],
      "metadata": {
        "id": "PAKAmYtcgVgu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download(\"all\")"
      ],
      "metadata": {
        "id": "VGkXZgnBgmta"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from wordcloud import WordCloud\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix"
      ],
      "metadata": {
        "id": "bOgiZzIcgr7P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df =pd.read_csv(\"/content/AI_Human.csv\")\n",
        "df.head()"
      ],
      "metadata": {
        "id": "GWHhaTQMhUfs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "id": "Q7-7Vg6lh2eh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe()"
      ],
      "metadata": {
        "id": "l5GapIpGiC7X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "L3pndwabiFqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.isnull().sum()"
      ],
      "metadata": {
        "id": "4B7sTxLhiJfI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.duplicated().sum()"
      ],
      "metadata": {
        "id": "xDHaueb0iMxJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize = (10,6))\n",
        "sns.countplot(x=\"generated\",data =df, palette = [\"green\",\"yellow\"])\n",
        "plt.gca().set_xticklabels([\"Human\",\"Generated\"])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "NA_wZhREWHQG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"generated\"].value_counts()"
      ],
      "metadata": {
        "id": "mx-8hUm78lrE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_0 = df[df['generated'] == 0].copy()\n",
        "df_1 = df[df['generated'] == 1].copy()"
      ],
      "metadata": {
        "id": "aI6BoofQn0PI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_0= df_0[:5000]\n",
        "df_1= df_1[:5000]"
      ],
      "metadata": {
        "id": "ubyUuVMMoXTx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.concat([df_0,df_1], ignore_index=True)\n",
        "df.shape"
      ],
      "metadata": {
        "id": "v6EEQe5RocAw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize = (10,6))\n",
        "sns.countplot(x=\"generated\",data =df, palette = [\"green\",\"yellow\"])\n",
        "plt.gca().set_xticklabels([\"Human\",\"Generated\"])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Pxw1KYDJomeC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"text\"] = df[\"text\"].str.lower()"
      ],
      "metadata": {
        "id": "Gplu3j46ibwD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "qnDAWdYCii17"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download(\"punkt\")\n",
        "df[\"tokens\"] = df[\"text\"].apply(word_tokenize)"
      ],
      "metadata": {
        "id": "JvgST0RYilgE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('stopwords')\n",
        "stop_words = set(stopwords.words('english'))\n",
        "df['tokens'] = df['tokens'].apply(lambda tokens: [word for word in tokens if word not in stop_words])"
      ],
      "metadata": {
        "id": "x7wW-XJBjDAn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "nltk.download('wordnet')\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "df['tokens'] = df['tokens'].apply(lambda tokens: [lemmatizer.lemmatize(word) for word in tokens])"
      ],
      "metadata": {
        "id": "queAaoy4B6f5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['preprocessed_text'] = df['tokens'].apply(lambda tokens: ' '.join(tokens))"
      ],
      "metadata": {
        "id": "2yU_Rgeao_TW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "Kwy3XbyhpAON"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "selected_columns = ['generated', 'preprocessed_text']\n",
        "df_Final = df[selected_columns]\n",
        "print(df_Final.head())"
      ],
      "metadata": {
        "id": "JKhMQNSXpARs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_Final.shape"
      ],
      "metadata": {
        "id": "_1lx7ymXpGmS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from wordcloud import WordCloud\n",
        "import matplotlib.pyplot as plt\n",
        "df_class_0 = df_Final[df_Final['generated'] == 0]\n",
        "wordcloud_class_0 = WordCloud(width=800, height=400, background_color='white').generate(' '.join(df_class_0['preprocessed_text']))\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.imshow(wordcloud_class_0, interpolation='bilinear')\n",
        "plt.title('WordCloud for  Human')\n",
        "plt.axis('off')\n",
        "plt.show()\n",
        "df_class_1 = df_Final[df_Final['generated'] == 1]\n",
        "wordcloud_class_1 = WordCloud(width=800, height=400, background_color='white').generate(' '.join(df_class_1['preprocessed_text']))\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.imshow(wordcloud_class_1, interpolation='bilinear')\n",
        "plt.title('WordCloud for Class AI')\n",
        "plt.axis('off')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "paDIYAWppNUG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = df_Final['preprocessed_text']\n",
        "y = df_Final['generated']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "u0XzYO5GpYrK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "tfidf_vectorizer = TfidfVectorizer(max_features=5000)\n",
        "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
        "X_test_tfidf = tfidf_vectorizer.transform(X_test)"
      ],
      "metadata": {
        "id": "ToHa2G26pfXp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "svm_model = SVC()\n",
        "svm_model.fit(X_train_tfidf, y_train)\n",
        "svm_predictions = svm_model.predict(X_test_tfidf)\n",
        "\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "print(\"Accuracy:\", accuracy_score(y_test, svm_predictions))\n",
        "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, svm_predictions))\n",
        "train_predictions = svm_model.predict(X_train_tfidf)\n",
        "\n",
        "print(\"Training Classification Report:\\n\", classification_report(y_train, train_predictions))\n",
        "test_predictions = svm_model.predict(X_test_tfidf)\n",
        "print(\"\\nTesting Classification Report:\\n\", classification_report(y_test, test_predictions))"
      ],
      "metadata": {
        "id": "ahO5iF4qpfa8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "model = MultinomialNB()\n",
        "model.fit(X_train_tfidf, y_train)"
      ],
      "metadata": {
        "id": "yYCM2jlIp4zQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "predictions = model.predict(X_test_tfidf)\n",
        "print(\"Accuracy:\", accuracy_score(y_test, predictions))\n",
        "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, predictions))\n",
        "train_predictions = model.predict(X_train_tfidf)\n",
        "print(\"Training Classification Report:\\n\", classification_report(y_train, train_predictions))\n",
        "test_predictions = model.predict(X_test_tfidf)\n",
        "print(\"\\nTesting Classification Report:\\n\", classification_report(y_test, test_predictions))"
      ],
      "metadata": {
        "id": "QpwI6Tznp41W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_Final.head()"
      ],
      "metadata": {
        "id": "5FUi-9O7p44u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_data = [\"failure common occurrence one everyone must\"]\n",
        "new_data_tfidf = tfidf_vectorizer.transform(new_data)\n",
        "predictions = svm_model.predict(new_data_tfidf)\n",
        "print(\"SVM Predictions:\")\n",
        "print(predictions)"
      ],
      "metadata": {
        "id": "sDe8gLDNqOfN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_data = [\"america love affair vehicle seems cooling say\"]\n",
        "new_data_tfidf = tfidf_vectorizer.transform(new_data)\n",
        "predictions = svm_model.predict(new_data_tfidf)\n",
        "print(\"SVM Predictions:\")\n",
        "print(predictions)"
      ],
      "metadata": {
        "id": "DJNzfmv6qTFq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_data = [\"failure common occurrence one everyone must\"]\n",
        "new_data_tfidf = tfidf_vectorizer.transform(new_data)\n",
        "nb_predictions = model.predict(new_data_tfidf)\n",
        "\n",
        "print(\"Naive Bayes Predictions:\")\n",
        "print(nb_predictions)"
      ],
      "metadata": {
        "id": "8-ueyHlZqWVQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_data = [\"america love affair vehicle seems cooling say\"]\n",
        "new_data_tfidf = tfidf_vectorizer.transform(new_data)\n",
        "nb_predictions = model.predict(new_data_tfidf)\n",
        "\n",
        "print(\"Naive Bayes Predictions:\")\n",
        "print(nb_predictions)"
      ],
      "metadata": {
        "id": "5RJzuO6EqZQN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}